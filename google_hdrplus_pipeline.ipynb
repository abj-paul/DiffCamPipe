{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c56f6893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rawpy\n",
      "  Downloading rawpy-0.24.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./envDiffCamPipe/lib/python3.12/site-packages (from rawpy) (2.2.4)\n",
      "Downloading rawpy-0.24.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m603.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rawpy\n",
      "Successfully installed rawpy-0.24.0\n"
     ]
    }
   ],
   "source": [
    "!pip install rawpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d44c2972",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No files found with pattern: path/to/your/raw/files/*.CR2",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 700\u001b[39m\n\u001b[32m    697\u001b[39m     hdr_plus.save_image(output_image, \u001b[33m\"\u001b[39m\u001b[33mhdr_plus_output.jpg\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    699\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m700\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 691\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    688\u001b[39m hdr_plus = HDRPlus(tile_size=\u001b[32m16\u001b[39m, search_region=\u001b[32m4\u001b[39m, pyramid_levels=\u001b[32m3\u001b[39m, num_frames=\u001b[32m8\u001b[39m)\n\u001b[32m    690\u001b[39m \u001b[38;5;66;03m# Load raw burst (this would be your raw files)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m691\u001b[39m raw_burst = \u001b[43mhdr_plus\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_raw_burst\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpath/to/your/raw/files/*.CR2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[38;5;66;03m# Process pipeline\u001b[39;00m\n\u001b[32m    694\u001b[39m output_image = hdr_plus.process_pipeline(raw_burst)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 46\u001b[39m, in \u001b[36mHDRPlus.load_raw_burst\u001b[39m\u001b[34m(self, file_pattern)\u001b[39m\n\u001b[32m     44\u001b[39m files = \u001b[38;5;28msorted\u001b[39m(glob.glob(file_pattern))[:\u001b[38;5;28mself\u001b[39m.num_frames]\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(files) == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo files found with pattern: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_pattern\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     48\u001b[39m raw_images = []\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:\n",
      "\u001b[31mValueError\u001b[39m: No files found with pattern: path/to/your/raw/files/*.CR2"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from scipy import ndimage\n",
    "import rawpy\n",
    "import imageio\n",
    "import os\n",
    "import glob\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "class HDRPlus:\n",
    "    def __init__(self, tile_size=16, search_region=4, pyramid_levels=3, num_frames=8):\n",
    "        \"\"\"\n",
    "        Initialize the HDR+ pipeline\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        tile_size: int\n",
    "            Size of tiles for alignment and merging (default: 16)\n",
    "        search_region: int\n",
    "            Size of the search region around each tile (default: 4)\n",
    "        pyramid_levels: int\n",
    "            Number of levels in the Gaussian pyramid for alignment (default: 3)\n",
    "        num_frames: int\n",
    "            Number of frames to process in a burst (default: 8)\n",
    "        \"\"\"\n",
    "        self.tile_size = tile_size\n",
    "        self.search_region = search_region\n",
    "        self.pyramid_levels = pyramid_levels\n",
    "        self.num_frames = num_frames\n",
    "\n",
    "    def load_raw_burst(self, file_pattern):\n",
    "        \"\"\"\n",
    "        Load a burst of raw images\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        file_pattern: str\n",
    "            Pattern to glob for raw files\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        list of raw images\n",
    "        \"\"\"\n",
    "        files = sorted(glob.glob(file_pattern))[:self.num_frames]\n",
    "        if len(files) == 0:\n",
    "            raise ValueError(f\"No files found with pattern: {file_pattern}\")\n",
    "        \n",
    "        raw_images = []\n",
    "        for file in files:\n",
    "            with rawpy.imread(file) as raw:\n",
    "                # Get raw data without processing\n",
    "                raw_data = raw.raw_image.copy()\n",
    "                # Store raw object metadata\n",
    "                bayer_pattern = raw.raw_pattern\n",
    "                black_level = raw.black_level_per_channel[0]  # Assuming same black level for all channels\n",
    "                white_level = raw.white_level\n",
    "                \n",
    "                raw_images.append({\n",
    "                    'data': raw_data,\n",
    "                    'bayer_pattern': bayer_pattern,\n",
    "                    'black_level': black_level,\n",
    "                    'white_level': white_level,\n",
    "                    'camera_white_balance': raw.camera_white_balance,\n",
    "                    'color_matrix': raw.color_matrix\n",
    "                })\n",
    "        \n",
    "        print(f\"Loaded {len(raw_images)} raw frames\")\n",
    "        return raw_images\n",
    "\n",
    "    def preprocess_raw(self, raw_image):\n",
    "        \"\"\"\n",
    "        Preprocess raw image for alignment\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        raw_image: dict\n",
    "            Raw image data and metadata\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        Preprocessed image for alignment\n",
    "        \"\"\"\n",
    "        # Subtract black level\n",
    "        data = raw_image['data'].astype(np.float32)\n",
    "        data -= raw_image['black_level']\n",
    "        \n",
    "        # Simple demosaic for alignment purpose only\n",
    "        # This is a simplified version - real implementation would be more sophisticated\n",
    "        h, w = data.shape\n",
    "        processed = np.zeros((h, w, 3), dtype=np.float32)\n",
    "        \n",
    "        # Simple bilinear demosaicking based on Bayer pattern\n",
    "        # This is oversimplified and would need to be replaced with proper demosaicking\n",
    "        # for the actual implementation\n",
    "        \n",
    "        # Normalize\n",
    "        processed /= raw_image['white_level'] - raw_image['black_level']\n",
    "        \n",
    "        # Convert to grayscale for alignment\n",
    "        gray = np.mean(processed, axis=2)\n",
    "        \n",
    "        return gray\n",
    "\n",
    "    def build_pyramid(self, image):\n",
    "        \"\"\"\n",
    "        Build a Gaussian pyramid for alignment\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        image: ndarray\n",
    "            Input image\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        List of pyramid levels\n",
    "        \"\"\"\n",
    "        pyramid = [image]\n",
    "        current = image\n",
    "        \n",
    "        for _ in range(self.pyramid_levels - 1):\n",
    "            # Downsample by factor of 4 as described in the document\n",
    "            current = cv2.resize(current, (current.shape[1] // 4, current.shape[0] // 4))\n",
    "            pyramid.append(current)\n",
    "        \n",
    "        # Reverse to start with coarsest level\n",
    "        return pyramid[::-1]\n",
    "\n",
    "    def align_frames(self, frames):\n",
    "        \"\"\"\n",
    "        Align frames hierarchically using a Gaussian pyramid\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        frames: list\n",
    "            List of preprocessed frames\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        List of alignment vectors for each tile in the reference frame\n",
    "        \"\"\"\n",
    "        # Preprocess frames for alignment\n",
    "        preprocessed_frames = [self.preprocess_raw(frame) for frame in frames]\n",
    "        \n",
    "        # Choose the middle frame as reference\n",
    "        reference_idx = len(frames) // 2\n",
    "        reference = preprocessed_frames[reference_idx]\n",
    "        \n",
    "        # Build pyramids for all frames\n",
    "        pyramids = [self.build_pyramid(frame) for frame in preprocessed_frames]\n",
    "        reference_pyramid = pyramids[reference_idx]\n",
    "        \n",
    "        # Initialize alignment vectors (will be refined at each level)\n",
    "        h, w = frames[0]['data'].shape\n",
    "        tiles_y = h // self.tile_size\n",
    "        tiles_x = w // self.tile_size\n",
    "        \n",
    "        # Initialize alignment vectors as zeros\n",
    "        alignments = [np.zeros((tiles_y, tiles_x, 2), dtype=np.int32) for _ in range(len(frames))]\n",
    "        \n",
    "        # Process pyramid levels from coarse to fine\n",
    "        for level in range(len(reference_pyramid)):\n",
    "            level_ref = reference_pyramid[level]\n",
    "            \n",
    "            # Current scale factor\n",
    "            scale = 4 ** (self.pyramid_levels - level - 1)\n",
    "            \n",
    "            # Process each frame\n",
    "            for f, frame_pyramid in enumerate(pyramids):\n",
    "                if f == reference_idx:\n",
    "                    continue  # Skip reference frame\n",
    "                \n",
    "                level_frame = frame_pyramid[level]\n",
    "                \n",
    "                # Adjust tile size and search region for this pyramid level\n",
    "                level_tile_size = max(self.tile_size // scale, 4)\n",
    "                level_search = max(self.search_region // scale, 2)\n",
    "                \n",
    "                # Calculate alignments for this level\n",
    "                h_level, w_level = level_ref.shape\n",
    "                tiles_y_level = h_level // level_tile_size\n",
    "                tiles_x_level = w_level // level_tile_size\n",
    "                \n",
    "                for ty in range(tiles_y_level):\n",
    "                    for tx in range(tiles_x_level):\n",
    "                        # Get reference tile\n",
    "                        y_start = ty * level_tile_size\n",
    "                        x_start = tx * level_tile_size\n",
    "                        ref_tile = level_ref[y_start:y_start + level_tile_size, \n",
    "                                             x_start:x_start + level_tile_size]\n",
    "                        \n",
    "                        # Get previous alignment (if not at coarsest level)\n",
    "                        if level > 0:\n",
    "                            prev_ty = ty // 4\n",
    "                            prev_tx = tx // 4\n",
    "                            offset_y, offset_x = alignments[f][prev_ty, prev_tx] * 4\n",
    "                        else:\n",
    "                            offset_y, offset_x = 0, 0\n",
    "                        \n",
    "                        # Search around previous alignment\n",
    "                        best_dist = float('inf')\n",
    "                        best_dy, best_dx = 0, 0\n",
    "                        \n",
    "                        for dy in range(-level_search, level_search + 1):\n",
    "                            for dx in range(-level_search, level_search + 1):\n",
    "                                # Candidate position to check\n",
    "                                cand_y = y_start + offset_y + dy\n",
    "                                cand_x = x_start + offset_x + dx\n",
    "                                \n",
    "                                # Skip if out of bounds\n",
    "                                if (cand_y < 0 or cand_x < 0 or \n",
    "                                    cand_y + level_tile_size > h_level or \n",
    "                                    cand_x + level_tile_size > w_level):\n",
    "                                    continue\n",
    "                                \n",
    "                                # Get candidate tile\n",
    "                                cand_tile = level_frame[cand_y:cand_y + level_tile_size, \n",
    "                                                       cand_x:cand_x + level_tile_size]\n",
    "                                \n",
    "                                # Compute L1 distance as described in the document\n",
    "                                dist = np.sum(np.abs(ref_tile - cand_tile))\n",
    "                                \n",
    "                                if dist < best_dist:\n",
    "                                    best_dist = dist\n",
    "                                    best_dy = offset_y + dy\n",
    "                                    best_dx = offset_x + dx\n",
    "                        \n",
    "                        # Store alignment for this level\n",
    "                        if level == len(reference_pyramid) - 1:  # Finest level\n",
    "                            alignments[f][ty, tx] = [best_dy, best_dx]\n",
    "                        else:\n",
    "                            # Scale up for next level\n",
    "                            scaled_ty = min(ty * 4, tiles_y - 1)\n",
    "                            scaled_tx = min(tx * 4, tiles_x - 1)\n",
    "                            alignments[f][scaled_ty, scaled_tx] = [best_dy, best_dx]\n",
    "        \n",
    "        return alignments, reference_idx\n",
    "\n",
    "    def merge_frames(self, raw_frames, alignments, reference_idx):\n",
    "        \"\"\"\n",
    "        Merge aligned frames using a patch-based approach\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        raw_frames: list\n",
    "            List of raw frames\n",
    "        alignments: list\n",
    "            List of alignment vectors for each tile in each frame\n",
    "        reference_idx: int\n",
    "            Index of the reference frame\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        Merged raw frame\n",
    "        \"\"\"\n",
    "        reference = raw_frames[reference_idx]['data']\n",
    "        h, w = reference.shape\n",
    "        tiles_y = h // self.tile_size\n",
    "        tiles_x = w // self.tile_size\n",
    "        \n",
    "        # Create output merged frame\n",
    "        merged = np.zeros_like(reference, dtype=np.float32)\n",
    "        weights = np.zeros((h, w), dtype=np.float32)\n",
    "        \n",
    "        # Create raised cosine window for blending tiles\n",
    "        window = self.create_raised_cosine_window(self.tile_size)\n",
    "        \n",
    "        # Half overlap of tiles\n",
    "        half_tile = self.tile_size // 2\n",
    "        \n",
    "        # Process each tile with half-tile overlap\n",
    "        for ty in range(0, tiles_y * 2 - 1):\n",
    "            for tx in range(0, tiles_x * 2 - 1):\n",
    "                # Tile coordinates with half-tile steps\n",
    "                y_start = ty * half_tile\n",
    "                x_start = tx * half_tile\n",
    "                \n",
    "                # Ensure we don't go out of bounds\n",
    "                if y_start + self.tile_size > h or x_start + self.tile_size > w:\n",
    "                    continue\n",
    "                \n",
    "                # Get reference tile\n",
    "                ref_tile = reference[y_start:y_start + self.tile_size, \n",
    "                                    x_start:x_start + self.tile_size]\n",
    "                \n",
    "                # Collect aligned tiles from all frames\n",
    "                aligned_tiles = []\n",
    "                tile_weights = []\n",
    "                \n",
    "                for f, frame in enumerate(raw_frames):\n",
    "                    if f == reference_idx:\n",
    "                        aligned_tiles.append(ref_tile)\n",
    "                        tile_weights.append(1.0)  # Reference frame gets full weight\n",
    "                        continue\n",
    "                    \n",
    "                    # Get alignment for the nearest full tile\n",
    "                    nearest_ty = min(ty // 2, tiles_y - 1)\n",
    "                    nearest_tx = min(tx // 2, tiles_x - 1)\n",
    "                    dy, dx = alignments[f][nearest_ty, nearest_tx]\n",
    "                    \n",
    "                    # Extract aligned tile\n",
    "                    aligned_y = y_start + dy\n",
    "                    aligned_x = x_start + dx\n",
    "                    \n",
    "                    # Skip if out of bounds\n",
    "                    if (aligned_y < 0 or aligned_x < 0 or \n",
    "                        aligned_y + self.tile_size > h or \n",
    "                        aligned_x + self.tile_size > w):\n",
    "                        continue\n",
    "                    \n",
    "                    aligned_tile = frame['data'][aligned_y:aligned_y + self.tile_size, \n",
    "                                                aligned_x:aligned_x + self.tile_size]\n",
    "                    \n",
    "                    # Calculate similarity to reference tile (simplified patch similarity)\n",
    "                    diff = np.abs(ref_tile.astype(np.float32) - aligned_tile.astype(np.float32))\n",
    "                    similarity = np.exp(-np.mean(diff) / 30.0)  # Adjust this parameter as needed\n",
    "                    \n",
    "                    aligned_tiles.append(aligned_tile)\n",
    "                    tile_weights.append(similarity)\n",
    "                \n",
    "                # Normalize weights\n",
    "                tile_weights = np.array(tile_weights)\n",
    "                tile_weights /= np.sum(tile_weights)\n",
    "                \n",
    "                # Compute weighted average\n",
    "                merged_tile = np.zeros_like(ref_tile, dtype=np.float32)\n",
    "                for i, tile in enumerate(aligned_tiles):\n",
    "                    merged_tile += tile * tile_weights[i]\n",
    "                \n",
    "                # Apply window and add to output\n",
    "                merged[y_start:y_start + self.tile_size, \n",
    "                       x_start:x_start + self.tile_size] += merged_tile * window\n",
    "                weights[y_start:y_start + self.tile_size, \n",
    "                        x_start:x_start + self.tile_size] += window\n",
    "        \n",
    "        # Normalize by weights\n",
    "        merged /= np.maximum(weights, 1e-6)\n",
    "        \n",
    "        # Create merged raw frame with metadata from reference\n",
    "        merged_frame = raw_frames[reference_idx].copy()\n",
    "        merged_frame['data'] = merged\n",
    "        \n",
    "        return merged_frame\n",
    "\n",
    "    def create_raised_cosine_window(self, size):\n",
    "        \"\"\"\n",
    "        Create a 2D raised cosine window for tile blending\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        size: int\n",
    "            Size of the window\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        2D raised cosine window\n",
    "        \"\"\"\n",
    "        x = np.linspace(-1, 1, size)\n",
    "        X, Y = np.meshgrid(x, x)\n",
    "        R = np.sqrt(X**2 + Y**2)\n",
    "        R = np.clip(R, 0, 1)\n",
    "        \n",
    "        # Raised cosine function: 0.5 * (1 + cos(π*r))\n",
    "        window = 0.5 * (1 + np.cos(np.pi * R))\n",
    "        \n",
    "        return window\n",
    "\n",
    "    def demosaic(self, raw_data, bayer_pattern):\n",
    "        \"\"\"\n",
    "        Simplified demosaicking with gradient correction\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        raw_data: ndarray\n",
    "            Raw image data\n",
    "        bayer_pattern: ndarray\n",
    "            Bayer pattern\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        Demosaicked RGB image\n",
    "        \"\"\"\n",
    "        # For simplicity, we'll use OpenCV's demosaicking function\n",
    "        # In a real implementation, you'd want to implement the advanced\n",
    "        # demosaicking algorithm described in the paper\n",
    "        \n",
    "        # Convert to OpenCV's Bayer pattern format\n",
    "        # This is a placeholder - real implementation would need proper pattern detection\n",
    "        cv_bayer_pattern = cv2.COLOR_BAYER_RG2RGB\n",
    "        \n",
    "        # Ensure data is in correct format\n",
    "        raw_data = raw_data.astype(np.uint16)\n",
    "        \n",
    "        # Demosaic\n",
    "        rgb = cv2.cvtColor(raw_data, cv_bayer_pattern)\n",
    "        \n",
    "        # Normalize to [0, 1]\n",
    "        rgb = rgb.astype(np.float32) / 65535.0\n",
    "        \n",
    "        return rgb\n",
    "\n",
    "    def chroma_denoise(self, rgb):\n",
    "        \"\"\"\n",
    "        Apply bilinear chroma denoising\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        rgb: ndarray\n",
    "            RGB image\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        Denoised RGB image\n",
    "        \"\"\"\n",
    "        # Convert to YUV\n",
    "        y = 0.299 * rgb[:,:,0] + 0.587 * rgb[:,:,1] + 0.114 * rgb[:,:,2]\n",
    "        u = -0.14713 * rgb[:,:,0] - 0.28886 * rgb[:,:,1] + 0.436 * rgb[:,:,2]\n",
    "        v = 0.615 * rgb[:,:,0] - 0.51499 * rgb[:,:,1] - 0.10001 * rgb[:,:,2]\n",
    "        \n",
    "        # Apply bilateral filter to chroma channels\n",
    "        u_denoised = cv2.bilateralFilter(u, 9, 75, 75)\n",
    "        v_denoised = cv2.bilateralFilter(v, 9, 75, 75)\n",
    "        \n",
    "        # Convert back to RGB\n",
    "        r = y + 1.13983 * v_denoised\n",
    "        g = y - 0.39465 * u_denoised - 0.58060 * v_denoised\n",
    "        b = y + 2.03211 * u_denoised\n",
    "        \n",
    "        # Clip values to [0, 1]\n",
    "        denoised_rgb = np.stack([r, g, b], axis=2)\n",
    "        denoised_rgb = np.clip(denoised_rgb, 0, 1)\n",
    "        \n",
    "        return denoised_rgb\n",
    "\n",
    "    def apply_color_correction(self, rgb, color_matrix):\n",
    "        \"\"\"\n",
    "        Apply sRGB color correction\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        rgb: ndarray\n",
    "            RGB image\n",
    "        color_matrix: ndarray\n",
    "            Color matrix from metadata\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        Color corrected image\n",
    "        \"\"\"\n",
    "        # Reshape color matrix to 3x3\n",
    "        if color_matrix.shape[0] > 9:  # Some cameras have a larger matrix\n",
    "            color_matrix = color_matrix[:9].reshape(3, 3)\n",
    "        \n",
    "        # Apply color correction\n",
    "        h, w, _ = rgb.shape\n",
    "        flat_rgb = rgb.reshape(-1, 3).T  # Reshape to 3 x (h*w)\n",
    "        corrected_flat = np.dot(color_matrix, flat_rgb).T\n",
    "        corrected = corrected_flat.reshape(h, w, 3)\n",
    "        \n",
    "        # Clip values to [0, 1]\n",
    "        corrected = np.clip(corrected, 0, 1)\n",
    "        \n",
    "        return corrected\n",
    "\n",
    "    def tone_map(self, image, strength=1.0, iterations=1):\n",
    "        \"\"\"\n",
    "        Apply tone mapping using a Laplacian pyramid\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        image: ndarray\n",
    "            Input image\n",
    "        strength: float\n",
    "            Strength of tone mapping\n",
    "        iterations: int\n",
    "            Number of iterations for high contrast scenes\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        Tone mapped image\n",
    "        \"\"\"\n",
    "        # Create a simulated brighter exposure\n",
    "        bright_exposure = np.power(image, 0.5) # Simulating brighter exposure\n",
    "        \n",
    "        # For each iteration\n",
    "        result = image.copy()\n",
    "        \n",
    "        for _ in range(iterations):\n",
    "            # Build Laplacian pyramids for both images\n",
    "            levels = 5\n",
    "            gaussian_pyr_orig = [result]\n",
    "            gaussian_pyr_bright = [bright_exposure]\n",
    "            \n",
    "            current_orig = result\n",
    "            current_bright = bright_exposure\n",
    "            \n",
    "            for _ in range(levels-1):\n",
    "                current_orig = cv2.pyrDown(current_orig)\n",
    "                gaussian_pyr_orig.append(current_orig)\n",
    "                \n",
    "                current_bright = cv2.pyrDown(current_bright)\n",
    "                gaussian_pyr_bright.append(current_bright)\n",
    "            \n",
    "            laplacian_pyr_orig = []\n",
    "            laplacian_pyr_bright = []\n",
    "            \n",
    "            for i in range(levels-1):\n",
    "                laplacian_orig = gaussian_pyr_orig[i] - cv2.pyrUp(gaussian_pyr_orig[i+1])\n",
    "                laplacian_pyr_orig.append(laplacian_orig)\n",
    "                \n",
    "                laplacian_bright = gaussian_pyr_bright[i] - cv2.pyrUp(gaussian_pyr_bright[i+1])\n",
    "                laplacian_pyr_bright.append(laplacian_bright)\n",
    "            \n",
    "            # Add the last levels\n",
    "            laplacian_pyr_orig.append(gaussian_pyr_orig[-1])\n",
    "            laplacian_pyr_bright.append(gaussian_pyr_bright[-1])\n",
    "            \n",
    "            # Calculate weights for blending based on normal distribution\n",
    "            # Ideal pixel value distribution is centered around 0.5\n",
    "            mean = 0.5\n",
    "            std = 0.2\n",
    "            \n",
    "            def weight_function(x):\n",
    "                return np.exp(-((x - mean) ** 2) / (2 * std ** 2))\n",
    "            \n",
    "            # Blend the Laplacian pyramids\n",
    "            blended_pyr = []\n",
    "            \n",
    "            for i in range(levels):\n",
    "                # Calculate weights\n",
    "                orig_weight = weight_function(gaussian_pyr_orig[i])\n",
    "                bright_weight = weight_function(gaussian_pyr_bright[i])\n",
    "                \n",
    "                # Normalize weights\n",
    "                total_weight = orig_weight + bright_weight\n",
    "                orig_weight = orig_weight / total_weight\n",
    "                bright_weight = bright_weight / total_weight\n",
    "                \n",
    "                # Blend\n",
    "                blended = laplacian_pyr_orig[i] * orig_weight + laplacian_pyr_bright[i] * bright_weight\n",
    "                blended_pyr.append(blended)\n",
    "            \n",
    "            # Reconstruct the image\n",
    "            result = blended_pyr[-1]\n",
    "            for i in range(levels-2, -1, -1):\n",
    "                result = cv2.pyrUp(result) + blended_pyr[i]\n",
    "        \n",
    "        # Adjust strength\n",
    "        if strength != 1.0:\n",
    "            result = image * (1 - strength) + result * strength\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def gamma_correction(self, image, gamma=2.2):\n",
    "        \"\"\"\n",
    "        Apply gamma correction\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        image: ndarray\n",
    "            Input image\n",
    "        gamma: float\n",
    "            Gamma value\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        Gamma corrected image\n",
    "        \"\"\"\n",
    "        return np.power(image, 1.0/gamma)\n",
    "\n",
    "    def unsharp_mask(self, image, strength=0.5):\n",
    "        \"\"\"\n",
    "        Apply unsharp mask sharpening\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        image: ndarray\n",
    "            Input image\n",
    "        strength: float\n",
    "            Strength of sharpening\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        Sharpened image\n",
    "        \"\"\"\n",
    "        blurred = cv2.GaussianBlur(image, (0, 0), 3)\n",
    "        sharpen = image + strength * (image - blurred)\n",
    "        sharpen = np.clip(sharpen, 0, 1)\n",
    "        \n",
    "        return sharpen\n",
    "\n",
    "    def adjust_contrast(self, image, strength=1.1):\n",
    "        \"\"\"\n",
    "        Apply global contrast adjustment\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        image: ndarray\n",
    "            Input image\n",
    "        strength: float\n",
    "            Contrast adjustment strength\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        Contrast adjusted image\n",
    "        \"\"\"\n",
    "        mean = np.mean(image)\n",
    "        contrast = mean + (image - mean) * strength\n",
    "        contrast = np.clip(contrast, 0, 1)\n",
    "        \n",
    "        return contrast\n",
    "\n",
    "    def process_pipeline(self, raw_burst):\n",
    "        \"\"\"\n",
    "        Apply full HDR+ pipeline to a burst of raw images\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        raw_burst: list\n",
    "            List of raw images\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        Processed RGB image\n",
    "        \"\"\"\n",
    "        print(\"Aligning frames...\")\n",
    "        alignments, reference_idx = self.align_frames(raw_burst)\n",
    "        \n",
    "        print(\"Merging frames...\")\n",
    "        merged_raw = self.merge_frames(raw_burst, alignments, reference_idx)\n",
    "        \n",
    "        print(\"Applying finishing steps...\")\n",
    "        # Black level subtraction already done during merging\n",
    "        \n",
    "        # White balance\n",
    "        wb = merged_raw['camera_white_balance'][:3]  # Get first 3 channels\n",
    "        wb = wb / wb[1]  # Normalize to green channel\n",
    "        \n",
    "        # Demosaic\n",
    "        rgb = self.demosaic(merged_raw['data'], merged_raw['bayer_pattern'])\n",
    "        \n",
    "        # Apply white balance\n",
    "        rgb[:,:,0] *= wb[0]\n",
    "        rgb[:,:,2] *= wb[2]\n",
    "        \n",
    "        # Chroma denoising\n",
    "        rgb = self.chroma_denoise(rgb)\n",
    "        \n",
    "        # Color correction\n",
    "        rgb = self.apply_color_correction(rgb, merged_raw['color_matrix'])\n",
    "        \n",
    "        # Tone mapping\n",
    "        rgb = self.tone_map(rgb, strength=1.0, iterations=2)\n",
    "        \n",
    "        # Gamma correction\n",
    "        rgb = self.gamma_correction(rgb)\n",
    "        \n",
    "        # Contrast adjustment\n",
    "        rgb = self.adjust_contrast(rgb)\n",
    "        \n",
    "        # Sharpening\n",
    "        rgb = self.unsharp_mask(rgb)\n",
    "        \n",
    "        return rgb\n",
    "\n",
    "    def save_image(self, image, output_path):\n",
    "        \"\"\"\n",
    "        Save processed image\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        image: ndarray\n",
    "            Processed image\n",
    "        output_path: str\n",
    "            Path to save the image\n",
    "        \"\"\"\n",
    "        # Convert to 8-bit\n",
    "        image_8bit = (image * 255).astype(np.uint8)\n",
    "        \n",
    "        # Save using imageio\n",
    "        imageio.imwrite(output_path, image_8bit)\n",
    "        print(f\"Saved output to {output_path}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Example usage of the HDR+ pipeline\n",
    "    \"\"\"\n",
    "    # Initialize HDR+ pipeline\n",
    "    hdr_plus = HDRPlus(tile_size=16, search_region=4, pyramid_levels=3, num_frames=8)\n",
    "    \n",
    "    # Load raw burst (this would be your raw files)\n",
    "    raw_burst = hdr_plus.load_raw_burst(\"path/to/your/raw/files/*.CR2\")\n",
    "    \n",
    "    # Process pipeline\n",
    "    output_image = hdr_plus.process_pipeline(raw_burst)\n",
    "    \n",
    "    # Save result\n",
    "    hdr_plus.save_image(output_image, \"hdr_plus_output.jpg\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352ebb46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envDiffCamPipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
