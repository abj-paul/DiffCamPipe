{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68c091dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b99498e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        self.fc = nn.Linear(32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# -------- Dataset Loader (CIFAR10 as example) --------\n",
    "transform_raw = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_data = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_raw)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "test_data = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_raw)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c28c68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToPILImage, ToTensor\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Create instances of the transform functions\n",
    "to_pil = ToPILImage()\n",
    "to_tensor = ToTensor()\n",
    "\n",
    "def apply_gaussian_blur(img):\n",
    "    img_pil = to_pil(img)  # Convert tensor to PIL\n",
    "    img_np = np.array(img_pil)  # Convert PIL to NumPy\n",
    "    img_blurred = cv2.GaussianBlur(img_np, (5, 5), sigmaX=0)\n",
    "    img_blurred_tensor = to_tensor(img_blurred)  # Back to tensor\n",
    "    return img_blurred_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ad20c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/75] - Loss: 0.0012\n",
      "Epoch [2/75] - Loss: 0.0013\n",
      "Epoch [3/75] - Loss: 0.0011\n",
      "Epoch [4/75] - Loss: 0.0012\n",
      "Epoch [5/75] - Loss: 0.0009\n",
      "Epoch [6/75] - Loss: 0.0012\n",
      "Epoch [7/75] - Loss: 0.0012\n",
      "Epoch [8/75] - Loss: 0.0009\n",
      "Epoch [9/75] - Loss: 0.0009\n",
      "Epoch [10/75] - Loss: 0.0009\n",
      "Epoch [11/75] - Loss: 0.0007\n",
      "Epoch [12/75] - Loss: 0.0012\n",
      "Epoch [13/75] - Loss: 0.0010\n",
      "Epoch [14/75] - Loss: 0.0012\n",
      "Epoch [15/75] - Loss: 0.0011\n",
      "Epoch [16/75] - Loss: 0.0007\n",
      "Epoch [17/75] - Loss: 0.0011\n",
      "Epoch [18/75] - Loss: 0.0011\n",
      "Epoch [19/75] - Loss: 0.0009\n",
      "Epoch [20/75] - Loss: 0.0009\n",
      "Epoch [21/75] - Loss: 0.0007\n",
      "Epoch [22/75] - Loss: 0.0008\n",
      "Epoch [23/75] - Loss: 0.0010\n",
      "Epoch [24/75] - Loss: 0.0011\n",
      "Epoch [25/75] - Loss: 0.0007\n",
      "Epoch [26/75] - Loss: 0.0011\n",
      "Epoch [27/75] - Loss: 0.0010\n",
      "Epoch [28/75] - Loss: 0.0011\n",
      "Epoch [29/75] - Loss: 0.0008\n",
      "Epoch [30/75] - Loss: 0.0011\n",
      "Epoch [31/75] - Loss: 0.0010\n",
      "Epoch [32/75] - Loss: 0.0011\n",
      "Epoch [33/75] - Loss: 0.0009\n",
      "Epoch [34/75] - Loss: 0.0013\n",
      "Epoch [35/75] - Loss: 0.0012\n",
      "Epoch [36/75] - Loss: 0.0009\n",
      "Epoch [37/75] - Loss: 0.0011\n",
      "Epoch [38/75] - Loss: 0.0006\n",
      "Epoch [39/75] - Loss: 0.0012\n",
      "Epoch [40/75] - Loss: 0.0007\n",
      "Epoch [41/75] - Loss: 0.0007\n",
      "Epoch [42/75] - Loss: 0.0009\n",
      "Epoch [43/75] - Loss: 0.0011\n",
      "Epoch [44/75] - Loss: 0.0005\n",
      "Epoch [45/75] - Loss: 0.0009\n",
      "Epoch [46/75] - Loss: 0.0008\n",
      "Epoch [47/75] - Loss: 0.0010\n",
      "Epoch [48/75] - Loss: 0.0010\n",
      "Epoch [49/75] - Loss: 0.0006\n",
      "Epoch [50/75] - Loss: 0.0006\n",
      "Epoch [51/75] - Loss: 0.0007\n",
      "Epoch [52/75] - Loss: 0.0010\n",
      "Epoch [53/75] - Loss: 0.0009\n",
      "Epoch [54/75] - Loss: 0.0009\n",
      "Epoch [55/75] - Loss: 0.0009\n",
      "Epoch [56/75] - Loss: 0.0007\n",
      "Epoch [57/75] - Loss: 0.0009\n",
      "Epoch [58/75] - Loss: 0.0008\n",
      "Epoch [59/75] - Loss: 0.0008\n",
      "Epoch [60/75] - Loss: 0.0007\n",
      "Epoch [61/75] - Loss: 0.0007\n",
      "Epoch [62/75] - Loss: 0.0008\n",
      "Epoch [63/75] - Loss: 0.0009\n",
      "Epoch [64/75] - Loss: 0.0009\n",
      "Epoch [65/75] - Loss: 0.0008\n",
      "Epoch [66/75] - Loss: 0.0012\n",
      "Epoch [67/75] - Loss: 0.0007\n",
      "Epoch [68/75] - Loss: 0.0010\n",
      "Epoch [69/75] - Loss: 0.0010\n",
      "Epoch [70/75] - Loss: 0.0009\n",
      "Epoch [71/75] - Loss: 0.0008\n",
      "Epoch [72/75] - Loss: 0.0007\n",
      "Epoch [73/75] - Loss: 0.0006\n",
      "Epoch [74/75] - Loss: 0.0009\n",
      "Epoch [75/75] - Loss: 0.0005\n",
      "Test Accuracy: 45.46%\n",
      "Model saved to gaussian_blur_pipeline.pth\n"
     ]
    }
   ],
   "source": [
    "# -------- Training loop --------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN(num_classes=10).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(75):  # Train only one epoch for testing\n",
    "    for images, labels in train_loader:\n",
    "        # Apply the non-differentiable filter to each image\n",
    "        filtered = torch.stack([apply_gaussian_blur(img) for img in images])\n",
    "        filtered = filtered.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(filtered)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/75] - Loss: {loss / len(train_loader):.4f}\")\n",
    "\n",
    "# -------- Evaluation --------\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "acc = correct / total\n",
    "print(f\"Test Accuracy: {acc * 100:.2f}%\")\n",
    "\n",
    "# -------- Save Model --------\n",
    "torch.save(model.state_dict(), \"gaussian_blur_pipeline.pth\")\n",
    "print(\"Model saved to gaussian_blur_pipeline.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e61c8f",
   "metadata": {},
   "source": [
    "### Gaussian Blur Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "993e3fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class GaussianBlur(nn.Module):\n",
    "    def __init__(self, kernel_size=5, sigma=1.0):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sigma = sigma\n",
    "        self.padding = kernel_size // 2\n",
    "        self.kernel = self.create_gaussian_kernel()\n",
    "\n",
    "    def create_gaussian_kernel(self):\n",
    "        k = self.kernel_size\n",
    "        sigma = self.sigma\n",
    "\n",
    "        # Create 1D Gaussian kernel\n",
    "        x = torch.arange(-k // 2 + 1., k // 2 + 1.)\n",
    "        gauss = torch.exp(-x**2 / (2 * sigma**2))\n",
    "        gauss = gauss / gauss.sum()\n",
    "\n",
    "        # Create 2D Gaussian kernel by outer product\n",
    "        kernel_2d = torch.outer(gauss, gauss)\n",
    "        kernel_2d = kernel_2d.expand(3, 1, k, k)  # [C_out, C_in/groups, H, W]\n",
    "        return kernel_2d\n",
    "\n",
    "    def forward(self, x):\n",
    "        kernel = self.kernel.to(x.device)\n",
    "        return F.conv2d(x, kernel, padding=self.padding, groups=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee1e7dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlurCameraPipeline(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.blur = GaussianBlur(kernel_size=5, sigma=1.0)\n",
    "        self.cnn = SimpleCNN(num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.blur(x)\n",
    "        return self.cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91f290ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/75] - Loss: 2.0624\n",
      "Epoch [2/75] - Loss: 1.9013\n",
      "Epoch [3/75] - Loss: 1.8339\n",
      "Epoch [4/75] - Loss: 1.7905\n",
      "Epoch [5/75] - Loss: 1.7480\n",
      "Epoch [6/75] - Loss: 1.7115\n",
      "Epoch [7/75] - Loss: 1.6839\n",
      "Epoch [8/75] - Loss: 1.6636\n",
      "Epoch [9/75] - Loss: 1.6441\n",
      "Epoch [10/75] - Loss: 1.6282\n",
      "Epoch [11/75] - Loss: 1.6130\n",
      "Epoch [12/75] - Loss: 1.6032\n",
      "Epoch [13/75] - Loss: 1.5916\n",
      "Epoch [14/75] - Loss: 1.5761\n",
      "Epoch [15/75] - Loss: 1.5664\n",
      "Epoch [16/75] - Loss: 1.5557\n",
      "Epoch [17/75] - Loss: 1.5441\n",
      "Epoch [18/75] - Loss: 1.5334\n",
      "Epoch [19/75] - Loss: 1.5268\n",
      "Epoch [20/75] - Loss: 1.5190\n",
      "Epoch [21/75] - Loss: 1.5107\n",
      "Epoch [22/75] - Loss: 1.5038\n",
      "Epoch [23/75] - Loss: 1.4980\n",
      "Epoch [24/75] - Loss: 1.4879\n",
      "Epoch [25/75] - Loss: 1.4822\n",
      "Epoch [26/75] - Loss: 1.4765\n",
      "Epoch [27/75] - Loss: 1.4703\n",
      "Epoch [28/75] - Loss: 1.4656\n",
      "Epoch [29/75] - Loss: 1.4572\n",
      "Epoch [30/75] - Loss: 1.4509\n",
      "Epoch [31/75] - Loss: 1.4452\n",
      "Epoch [32/75] - Loss: 1.4386\n",
      "Epoch [33/75] - Loss: 1.4319\n",
      "Epoch [34/75] - Loss: 1.4265\n",
      "Epoch [35/75] - Loss: 1.4238\n",
      "Epoch [36/75] - Loss: 1.4184\n",
      "Epoch [37/75] - Loss: 1.4115\n",
      "Epoch [38/75] - Loss: 1.4062\n",
      "Epoch [39/75] - Loss: 1.4033\n",
      "Epoch [40/75] - Loss: 1.3978\n",
      "Epoch [41/75] - Loss: 1.3957\n",
      "Epoch [42/75] - Loss: 1.3883\n",
      "Epoch [43/75] - Loss: 1.3862\n",
      "Epoch [44/75] - Loss: 1.3835\n",
      "Epoch [45/75] - Loss: 1.3796\n",
      "Epoch [46/75] - Loss: 1.3753\n",
      "Epoch [47/75] - Loss: 1.3704\n",
      "Epoch [48/75] - Loss: 1.3684\n",
      "Epoch [49/75] - Loss: 1.3665\n",
      "Epoch [50/75] - Loss: 1.3610\n",
      "Epoch [51/75] - Loss: 1.3583\n",
      "Epoch [52/75] - Loss: 1.3518\n",
      "Epoch [53/75] - Loss: 1.3521\n",
      "Epoch [54/75] - Loss: 1.3467\n",
      "Epoch [55/75] - Loss: 1.3468\n",
      "Epoch [56/75] - Loss: 1.3414\n",
      "Epoch [57/75] - Loss: 1.3373\n",
      "Epoch [58/75] - Loss: 1.3376\n",
      "Epoch [59/75] - Loss: 1.3322\n",
      "Epoch [60/75] - Loss: 1.3300\n",
      "Epoch [61/75] - Loss: 1.3279\n",
      "Epoch [62/75] - Loss: 1.3238\n",
      "Epoch [63/75] - Loss: 1.3233\n",
      "Epoch [64/75] - Loss: 1.3201\n",
      "Epoch [65/75] - Loss: 1.3175\n",
      "Epoch [66/75] - Loss: 1.3142\n",
      "Epoch [67/75] - Loss: 1.3125\n",
      "Epoch [68/75] - Loss: 1.3110\n",
      "Epoch [69/75] - Loss: 1.3094\n",
      "Epoch [70/75] - Loss: 1.3054\n",
      "Epoch [71/75] - Loss: 1.3029\n",
      "Epoch [72/75] - Loss: 1.3009\n",
      "Epoch [73/75] - Loss: 1.3007\n",
      "Epoch [74/75] - Loss: 1.2951\n",
      "Epoch [75/75] - Loss: 1.2962\n"
     ]
    }
   ],
   "source": [
    "model = BlurCameraPipeline(num_classes=10).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(75):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/75] - Loss: {running_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c6f81f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 54.26%\n",
      "Model saved to gaussian_blur_pipeline.pth\n"
     ]
    }
   ],
   "source": [
    "# -------- Evaluation --------\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "acc = correct / total\n",
    "print(f\"Test Accuracy: {acc * 100:.2f}%\")\n",
    "\n",
    "# -------- Save Model --------\n",
    "torch.save(model.state_dict(), \"differentiable_gaussian_blur_pipeline.pth\")\n",
    "print(\"Model saved to gaussian_blur_pipeline.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac0f84c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envDiffCamPipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
