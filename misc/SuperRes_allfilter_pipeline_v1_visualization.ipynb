{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b98f880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import cv2\n",
    "from typing import Tuple, List, Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "class SampledCelebA(Dataset):\n",
    "    def __init__(self, root_dir, attr_path, transform=None, sample_size=5000, seed=42):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images.\n",
    "            attr_path (string): Path to attributes file.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "            sample_size (int): Number of images to sample from the dataset.\n",
    "            seed (int): Random seed for reproducibility.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Set random seed for reproducibility\n",
    "        random.seed(seed)\n",
    "        \n",
    "        # Get all image filenames\n",
    "        all_image_files = os.listdir(root_dir)\n",
    "        \n",
    "        # Sample a subset of images\n",
    "        self.sample_size = min(sample_size, len(all_image_files))\n",
    "        self.image_files = random.sample(all_image_files, self.sample_size)\n",
    "        \n",
    "        # Read attributes (optional)\n",
    "        try:\n",
    "            self.attr_df = pd.read_csv(attr_path, delim_whitespace=True, header=1)\n",
    "        except:\n",
    "            print(\"Warning: Could not read attributes file. Will return zero attributes.\")\n",
    "            self.attr_df = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.sample_size\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.image_files[idx])\n",
    "        image = Image.open(img_name).convert('RGB')  # Ensure RGB format\n",
    "        \n",
    "        # Default empty attributes tensor\n",
    "        attributes = torch.zeros(40, dtype=torch.float32)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, attributes\n",
    "\n",
    "# Define transforms\n",
    "transform_raw = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "# 1. Sharpening Filter\n",
    "class SharpeningFilter(nn.Module):\n",
    "    def __init__(self, strength=1.0):\n",
    "        super().__init__()\n",
    "        kernel_init = torch.tensor([\n",
    "            [0, -1, 0],\n",
    "            [-1, 5, -1],\n",
    "            [0, -1, 0]\n",
    "        ], dtype=torch.float32)\n",
    "        \n",
    "        identity = torch.eye(3, dtype=torch.float32)\n",
    "        kernel_init = identity + (kernel_init - identity) * strength\n",
    "        \n",
    "        kernel_init = kernel_init.unsqueeze(0).unsqueeze(0)\n",
    "        self.kernel = nn.Parameter(kernel_init)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        out = torch.zeros_like(x)\n",
    "        for i in range(c):\n",
    "            channel = x[:, i:i+1, :, :]\n",
    "            out[:, i:i+1, :, :] = F.conv2d(\n",
    "                channel, \n",
    "                self.kernel.expand(1, 1, 3, 3),\n",
    "                padding=1\n",
    "            )\n",
    "        return torch.clamp(out, 0, 1)\n",
    "\n",
    "# 2. Edge Detection\n",
    "class SobelEdgeDetection(nn.Module):\n",
    "    def __init__(self, threshold=0.1):\n",
    "        super().__init__()\n",
    "        sobel_x = torch.tensor([\n",
    "            [-1, 0, 1],\n",
    "            [-2, 0, 2],\n",
    "            [-1, 0, 1]\n",
    "        ], dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        sobel_y = torch.tensor([\n",
    "            [-1, -2, -1],\n",
    "            [0, 0, 0],\n",
    "            [1, 2, 1]\n",
    "        ], dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        self.sobel_x = nn.Parameter(sobel_x)\n",
    "        self.sobel_y = nn.Parameter(sobel_y)\n",
    "        self.threshold = nn.Parameter(torch.tensor(threshold))\n",
    "        self.rgb_weights = nn.Parameter(torch.tensor([0.299, 0.587, 0.114], dtype=torch.float32))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        gray = torch.sum(x * self.rgb_weights.view(1, 3, 1, 1), dim=1, keepdim=True)\n",
    "        grad_x = F.conv2d(gray, self.sobel_x, padding=1)\n",
    "        grad_y = F.conv2d(gray, self.sobel_y, padding=1)\n",
    "        magnitude = torch.sqrt(grad_x**2 + grad_y**2 + 1e-8)\n",
    "        magnitude = magnitude / (torch.max(magnitude, dim=2, keepdim=True)[0].max(dim=3, keepdim=True)[0] + 1e-8)\n",
    "        edges = torch.sigmoid((magnitude - self.threshold) * 10)\n",
    "        return edges.repeat(1, 3, 1, 1)\n",
    "\n",
    "# 3. Median Filter\n",
    "class DifferentiableMedianFilter(nn.Module):\n",
    "    def __init__(self, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.pad = kernel_size // 2\n",
    "        self.temperature = nn.Parameter(torch.tensor(0.1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        x_padded = F.pad(x, (self.pad, self.pad, self.pad, self.pad), mode='reflect')\n",
    "        out = torch.zeros_like(x)\n",
    "        \n",
    "        for channel in range(c):\n",
    "            patches = F.unfold(x_padded[:, channel:channel+1, :, :], \n",
    "                              kernel_size=self.kernel_size, \n",
    "                              stride=1)\n",
    "            patches = patches.reshape(b, self.kernel_size*self.kernel_size, h*w)\n",
    "            sorted_patches, _ = torch.sort(patches, dim=1)\n",
    "            median_idx = self.kernel_size * self.kernel_size // 2\n",
    "            median_values = sorted_patches[:, median_idx, :]\n",
    "            out[:, channel, :, :] = median_values.reshape(b, h, w)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# 4. Contrast Enhancement\n",
    "class ContrastEnhancement(nn.Module):\n",
    "    def __init__(self, alpha=1.5, beta=0):\n",
    "        super().__init__()\n",
    "        self.alpha = nn.Parameter(torch.tensor(alpha, dtype=torch.float32))\n",
    "        self.beta = nn.Parameter(torch.tensor(beta, dtype=torch.float32))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        enhanced = self.alpha * x + self.beta\n",
    "        return torch.clamp(enhanced, 0, 1)\n",
    "\n",
    "# 5. Bilateral Filter\n",
    "class BilateralFilter(nn.Module):\n",
    "    def __init__(self, kernel_size=5, sigma_space=1.0, sigma_color=0.1):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sigma_space = nn.Parameter(torch.tensor(sigma_space))\n",
    "        self.sigma_color = nn.Parameter(torch.tensor(sigma_color))\n",
    "        self.padding = kernel_size // 2\n",
    "        \n",
    "        x = torch.arange(-(kernel_size // 2), kernel_size // 2 + 1, dtype=torch.float32)\n",
    "        y = torch.arange(-(kernel_size // 2), kernel_size // 2 + 1, dtype=torch.float32)\n",
    "        xx, yy = torch.meshgrid(x, y)\n",
    "        spatial_kernel = torch.exp(-(xx**2 + yy**2) / (2 * sigma_space**2))\n",
    "        self.register_buffer('spatial_kernel', spatial_kernel)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # For computational efficiency, we'll implement a simplified version\n",
    "        # for integration in the pipeline\n",
    "        b, c, h, w = x.shape\n",
    "        x_padded = F.pad(x, (self.padding, self.padding, self.padding, self.padding), mode='reflect')\n",
    "        \n",
    "        # Extract patches\n",
    "        patches = F.unfold(x_padded, kernel_size=self.kernel_size, stride=1)\n",
    "        patches = patches.view(b, c, self.kernel_size**2, h*w)\n",
    "        \n",
    "        # Get center pixels for each patch\n",
    "        center_idx = self.kernel_size**2 // 2\n",
    "        centers = patches[:, :, center_idx:center_idx+1, :]\n",
    "        \n",
    "        # Calculate color distance\n",
    "        color_diff = patches - centers\n",
    "        color_weight = torch.exp(-(color_diff**2) / (2 * self.sigma_color**2))\n",
    "        \n",
    "        # Apply spatial and color weights\n",
    "        weight = self.spatial_kernel.view(1, 1, -1, 1) * color_weight\n",
    "        weight = weight / (weight.sum(dim=2, keepdim=True) + 1e-8)\n",
    "        \n",
    "        # Apply weighted average\n",
    "        out = torch.sum(patches * weight, dim=2)\n",
    "        out = out.view(b, c, h, w)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# 6. Unsharp Masking\n",
    "class UnsharpMasking(nn.Module):\n",
    "    def __init__(self, strength=1.5, kernel_size=5, sigma=1.0):\n",
    "        super().__init__()\n",
    "        self.strength = nn.Parameter(torch.tensor(strength))\n",
    "        self.blur = GaussianBlur(kernel_size=kernel_size, sigma=sigma)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        blurred = self.blur(x)\n",
    "        mask = x - blurred\n",
    "        sharpened = x + self.strength * mask\n",
    "        return torch.clamp(sharpened, 0, 1)\n",
    "\n",
    "# --------------------------------\n",
    "# From your original code (reused)\n",
    "# --------------------------------\n",
    "\n",
    "# Gaussian Blur (from your original code)\n",
    "class GaussianBlur(nn.Module):\n",
    "    def __init__(self, kernel_size=5, sigma=1.5):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def forward(self, x):\n",
    "        channels = x.shape[1]\n",
    "        kernel_1d = torch.arange(self.kernel_size, dtype=torch.float32) - self.kernel_size // 2\n",
    "        kernel_1d = torch.exp(-kernel_1d ** 2 / (2 * self.sigma ** 2))\n",
    "        kernel_1d = kernel_1d / kernel_1d.sum()\n",
    "        kernel_2d = torch.outer(kernel_1d, kernel_1d)\n",
    "        kernel = kernel_2d.expand(channels, 1, -1, -1).to(x.device)\n",
    "        return F.conv2d(x, kernel, padding=self.kernel_size // 2, groups=channels)\n",
    "\n",
    "# White Balance (from your original code)\n",
    "class WhiteBalance(nn.Module):\n",
    "    def __init__(self, init_gains=(1.2, 1.0, 0.9)):\n",
    "        super().__init__()\n",
    "        self.gains = nn.Parameter(torch.tensor(init_gains, dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.gains.view(1, -1, 1, 1)\n",
    "\n",
    "# Gamma Correction (from your original code)\n",
    "class GammaCorrection(nn.Module):\n",
    "    def __init__(self, init_gamma=2.2):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.tensor(init_gamma))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.clamp(x, 1e-8, 1) ** (1 / self.gamma)\n",
    "\n",
    "# Upsampling CNN (from your original code)\n",
    "class UpsampleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "            nn.Conv2d(64, 3, 3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.upsample(x)\n",
    "\n",
    "# --------------------------------\n",
    "# Complete Pipeline Implementations\n",
    "# --------------------------------\n",
    "\n",
    "class CompletePipeline(nn.Module):\n",
    "    \"\"\"Complete differentiable image processing pipeline with filter, gamma correction, and upsampling\"\"\"\n",
    "    def __init__(self, filter_type='bilateral'):\n",
    "        super().__init__()\n",
    "        # Downsampling (fixed operation, not learnable)\n",
    "        self.downsample_factor = 0.5\n",
    "        \n",
    "        # Image processing components\n",
    "        self.white_balance = WhiteBalance(init_gains=(1.2, 1.0, 0.9))\n",
    "        \n",
    "        # Choose filter based on filter_type\n",
    "        if filter_type == 'sharpening':\n",
    "            self.filter = SharpeningFilter()\n",
    "        elif filter_type == 'edge_detection':\n",
    "            self.filter = SobelEdgeDetection()\n",
    "        elif filter_type == 'median':\n",
    "            self.filter = DifferentiableMedianFilter()\n",
    "        elif filter_type == 'contrast':\n",
    "            self.filter = ContrastEnhancement()\n",
    "        elif filter_type == 'bilateral':\n",
    "            self.filter = BilateralFilter()\n",
    "        elif filter_type == 'unsharp_masking':\n",
    "            self.filter = UnsharpMasking()\n",
    "        else:  # Default to Gaussian Blur\n",
    "            self.filter = GaussianBlur()\n",
    "        \n",
    "        # Gamma correction\n",
    "        self.gamma = GammaCorrection(init_gamma=2.2)\n",
    "        \n",
    "        # Upsampling CNN\n",
    "        self.upsample = UpsampleCNN()\n",
    "        \n",
    "        self.filter_type = filter_type\n",
    "    \n",
    "    def forward(self, x_hr):\n",
    "        # Downsample input (simulate low-res image)\n",
    "        x_lr = F.interpolate(x_hr, scale_factor=self.downsample_factor, mode='bicubic', align_corners=False)\n",
    "        \n",
    "        # Apply white balance\n",
    "        x_lr = self.white_balance(x_lr)\n",
    "        \n",
    "        # Apply specific filter\n",
    "        x_lr = self.filter(x_lr)\n",
    "        \n",
    "        # Apply gamma correction\n",
    "        x_lr = self.gamma(x_lr)\n",
    "        \n",
    "        # Apply upsampling CNN\n",
    "        x_sr = self.upsample(x_lr)\n",
    "        \n",
    "        return x_sr, x_lr  # Return both the final output and the filtered low-res image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6391a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing with bilateral filter =====\n",
      "BilateralFilter()\n",
      "\n",
      "===== Processing with sharpening filter =====\n",
      "SharpeningFilter()\n",
      "\n",
      "===== Processing with median filter =====\n",
      "DifferentiableMedianFilter()\n",
      "\n",
      "===== Processing with contrast filter =====\n",
      "ContrastEnhancement()\n",
      "\n",
      "===== Processing with unsharp_masking filter =====\n",
      "UnsharpMasking(\n",
      "  (blur): GaussianBlur()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------\n",
    "# Training and Evaluation\n",
    "# --------------------------------\n",
    "filter_types = [\n",
    "        'bilateral',       # Edge-preserving smoothing\n",
    "        'sharpening',      # Edge enhancement\n",
    "        'median',          # Noise reduction\n",
    "        'contrast',        # Contrast enhancement\n",
    "        'unsharp_masking'  # Another sharpening technique\n",
    "    ]\n",
    "for filter_type in filter_types:\n",
    "    print(f\"\\n===== Processing with {filter_type} filter =====\")\n",
    "    \n",
    "    pipeline = CompletePipeline(filter_type=filter_type)\n",
    "    print(pipeline.filter)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255673f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envDiffCamPipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
